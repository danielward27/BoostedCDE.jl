var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = BoostedCDE","category":"page"},{"location":"#BoostedCDE","page":"Home","title":"BoostedCDE","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for BoostedCDE.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [BoostedCDE]","category":"page"},{"location":"#BoostedCDE.BaseLearner","page":"Home","title":"BoostedCDE.BaseLearner","text":"Base learners are used to predict the negative gradient vector. These must all have the methods fit! and predict. Note that the same model is used multiple, so it must be safe to call the fit! method multiple times with different data.\n\n\n\n\n\n","category":"type"},{"location":"#BoostedCDE.BoostingModel","page":"Home","title":"BoostedCDE.BoostingModel","text":"Constructs a BoostingModel that can be trained using boost!\n\n\n\n\n\n","category":"type"},{"location":"#BoostedCDE.MeanCholeskyMvn","page":"Home","title":"BoostedCDE.MeanCholeskyMvn","text":"Parameterization of multivariate normal distribution with mean vector μ and the upper triangular component of the cholesky decomposition of the covariance matrix.\n\n\n\n\n\n","category":"type"},{"location":"#BoostedCDE.PolyBaseLearner","page":"Home","title":"BoostedCDE.PolyBaseLearner","text":"Base learner using polynomial transform. By defualt, with use_cache = true, the model will cache the feature vectors along with QR decompositions of the polynomial transforms to avoid recalculation. This will speed up training at the cost of increased memory usage. An IdDict is used as the cache.\n\n\n\n\n\n","category":"type"},{"location":"#BoostedCDE.boost!-Tuple{BoostingModel, AbstractMatrix{Float64}, AbstractMatrix{Float64}}","page":"Home","title":"BoostedCDE.boost!","text":"Fit a boosting model by performing M steps. Returns the \n\nboost!(model, θ, x; loss, steps)\n\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.fit!-Tuple{PolyBaseLearner, AbstractVector{T} where T, AbstractVector{T} where T}","page":"Home","title":"BoostedCDE.fit!","text":"Fit the Base learner model to the negative gradient vector uⱼ using feature vector θ.\n\nfit!(base_learner, θ, u)\n\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.gaussian_simulator-Tuple{Random.AbstractRNG, AbstractVector{Float64}}","page":"Home","title":"BoostedCDE.gaussian_simulator","text":"Simulate a three dimensional Gaussian mean vector θ. The covariance is diagonal, and fixed to σ=0.1. Parameter vector θ is the mean vector of the Gaussian.\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.loss-Tuple{Type{var\"#s16\"} where var\"#s16\"<:BoostedCDE.Abstractϕ, AbstractMatrix{Float64}, AbstractMatrix{Float64}}","page":"Home","title":"BoostedCDE.loss","text":"Loss function, if matrices used reduced using mean.\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.predict-Tuple{BoostingModel, AbstractMatrix{Float64}}","page":"Home","title":"BoostedCDE.predict","text":"Predict using the boosting model to get the conditional distributional parameters. Should provide the last ϕ matrix (from previous iteration) if known to avoid recalculating.\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.predict-Tuple{PolyBaseLearner, AbstractVector{T} where T}","page":"Home","title":"BoostedCDE.predict","text":"Predict the negative gradient vector using θ.\n\npredict(base_learner, θ)\n\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.reset!-Tuple{BoostingModel}","page":"Home","title":"BoostedCDE.reset!","text":"\"Reset\" the boosting model, removing all the selected base learners and corresponding indices.\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.step!-Tuple{BoostingModel, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}}","page":"Home","title":"BoostedCDE.step!","text":"Step the boosting model, by adding on a single new base model that minimizes the loss, returning the corresponding predictions ϕₘ, and loss in a tuple.\n\nstep!(model, θ, x, ϕₘ; loss)\n\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.tri_n_el_to_d-Tuple{Int64}","page":"Home","title":"BoostedCDE.tri_n_el_to_d","text":"Given the number of triangular elements in a matrix, get the dimension. \n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.unvectorize-Union{Tuple{T}, Tuple{Type{LinearAlgebra.UpperTriangular}, AbstractVector{T}}} where T","page":"Home","title":"BoostedCDE.unvectorize","text":"Given the array type and the vector, reform the array. This does the oposite transformation of vectorize\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.vectorize-Union{Tuple{LinearAlgebra.UpperTriangular{T, S} where S<:AbstractMatrix{T}}, Tuple{T}} where T","page":"Home","title":"BoostedCDE.vectorize","text":"Flatten to vector, with methods for special matrices, that ignore unwanted elements e.g. for diagonal matrices this will ignore off diagonal elements. These methods may return a copy or a view (behaviour is not kept consistent).\n\n\n\n\n\n","category":"method"},{"location":"#BoostedCDE.@loopify-Tuple{Any, Any}","page":"Home","title":"BoostedCDE.@loopify","text":"Convenience macro to define a method for a simulator that allows simulating in     batches. i.e. it takes simulator(rng::AbstractRNG, θ::AbstractVector{Float64}) and     wraps it in a for loop to get simulator(rng::AbstractRNG,     θ::Matrix{Float64}).\n\n\n\n\n\n","category":"macro"}]
}
